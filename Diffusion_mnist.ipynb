{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bdcfdff6",
      "metadata": {
        "id": "bdcfdff6"
      },
      "source": [
        "# Diffusion Models for Generative AI\n",
        "\n",
        "Diffusion models are a class of generative models that create new data by reversing a process that gradually adds noise. They operate in two main phases:\n",
        "\n",
        "- **Forward Process (Diffusion):** Noise is incrementally added to the original data over $T$ steps, transforming it into pure noise.\n",
        "- **Model Training:** The model learns to predict the noise added at each step, enabling it to understand how to reverse the process.\n",
        "- **Backward Process (Denoising):** Starting from random noise, the model iteratively removes noise over $T$ steps, reconstructing a new, realistic sample.\n",
        "\n",
        "This approach allows diffusion models to generate new high-quality images from a image dataset by simulating the process of denoising."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc080f89",
      "metadata": {
        "id": "cc080f89"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b58621e",
      "metadata": {
        "id": "3b58621e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "43e3c4e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43e3c4e1",
        "outputId": "d68f25cc-66f7-43ed-a065-641bf7f2b9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 483kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.55MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "mnist_train = mnist.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_test = mnist.MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52ac6abf",
      "metadata": {
        "id": "52ac6abf"
      },
      "source": [
        "### Forward Process - Noising\n",
        "\n",
        "Let $x_0$ be the image at t=0, and $x_t$ be the data at timestep $t$ after adding noise. The forward process is defined as:\n",
        "\n",
        "$$x_t = \\sqrt{\\alpha_t} x_{t-1} + \\sqrt{1 - \\alpha_t} \\epsilon_t,\\quad \\epsilon_t \\sim \\mathcal{N}(0, 1)$$\n",
        "\n",
        "$$q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\quad \\beta_t \\mathbf{I}),\\quad t \\sim \\mathcal{N}(0, T)$$\n",
        "\n",
        "\n",
        "\n",
        "where $\\beta_t = 1 - \\alpha_t$ is the variance schedule for timestep $t$.\n",
        "\n",
        "The cumulative process from $x_0$ to $x_t$:\n",
        "\n",
        "$$\n",
        "q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, \\quad (1 - \\bar{\\alpha}_t) \\mathbf{I})\n",
        "$$\n",
        "\n",
        "where $\\alpha_t = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s$.\n",
        "\n",
        "#### Algorithm\n",
        "\n",
        "1. **Initialize** $x_0$ as the original data sample.\n",
        "2. **For** $t = 1$ to $T$:\n",
        "    - Sample noise $\\epsilon_t \\sim \\mathcal{N}(0, \\mathbf{I})$\n",
        "    - Compute $x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_t$\n",
        "3. **Return** $x_T$ as the fully noised data.\n",
        "\n",
        "This process gradually transforms the original data into pure noise over $T$ steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7b20926f",
      "metadata": {
        "id": "7b20926f"
      },
      "outputs": [],
      "source": [
        "T = 30  # total timesteps\n",
        "a = 0.1 # noise proportion per step\n",
        "# kept constant for simplicity\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def Noising(images, T, a):\n",
        "    t = torch.randint(0, T, (images.size(0),), device=images.device).float()\n",
        "    noise = torch.randn_like(images)\n",
        "    a_t = a**t\n",
        "\n",
        "    noisy_images = (a_t.view(-1, 1, 1, 1))**0.5 * images + (1 - a_t).view(-1, 1, 1, 1)**0.5 * noise\n",
        "\n",
        "    return noisy_images, noise , t  # -> this should also be output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41ae8b8",
      "metadata": {
        "id": "c41ae8b8"
      },
      "source": [
        "### Deep Learning Model ###\n",
        "A simple CNN based model to run over-the image reduse the dimensions and atlast give an output $\\epsilon_t$.\\\n",
        "$\\epsilon_t$ is a prediction of the amount of error introduced. And, the model learns to predict $\\epsilon_t$ better and better.\n",
        "\n",
        "## U-NET Model Architecture\n",
        "\n",
        "This model is inspired by the **U-Net architecture**, with additional **time embeddings** to condition the network on the diffusion step `t`.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Components\n",
        "- **DoubleConv**: Two consecutive `Conv2d + ReLU` layers, used as the basic building block.  \n",
        "- **Down (Encoder path)**: `MaxPool2d` for downsampling, followed by `DoubleConv`. Captures hierarchical features.  \n",
        "- **Up (Decoder path)**: `Upsample` to increase spatial resolution, concatenates encoder features via skip connections, then applies `DoubleConv` to preserve fine details.  \n",
        "- **OutConv**: Final `1×1 convolution` to reduce channels to match output image size.  \n",
        "- **Time Embedding (`time_mlp`)**: Small MLP that processes the diffusion step `t` into an embedding, conditioning the model on the current timestep.\n",
        "\n",
        "---\n",
        "\n",
        "### Forward Pass\n",
        "1. Input image `x` goes through the encoder:  \n",
        "   `inc → down1 → down2 → down3 → down4`  \n",
        "2. Decoder reconstructs the image with skip connections:  \n",
        "   `up1(x5, x4) → up2(x, x3) → up3(x, x2) → up4(x, x1)`  \n",
        "3. Final output produced with `OutConv`.  \n",
        "4. Diffusion step `t` is embedded via `time_mlp` and conditions the model during training.\n",
        "\n",
        "---\n",
        "\n",
        "### Model Usage\n",
        "- **Input**: noisy image `x` and diffusion step `t`  \n",
        "- **Output**: predicted denoised image (same shape as `x`)  \n",
        "\n",
        "This design makes the model suitable for **denoising diffusion probabilistic models (DDPMs)** and other generative tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a7cb3b0b",
      "metadata": {
        "id": "a7cb3b0b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Diffusion(nn.Module):\n",
        "    def __init__(self, img_channels=1, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.inc = DoubleConv(img_channels, hidden_dim)\n",
        "        self.down1 = Down(hidden_dim, hidden_dim * 2)\n",
        "        self.down2 = Down(hidden_dim * 2, hidden_dim * 4)\n",
        "        self.down3 = Down(hidden_dim * 4, hidden_dim * 8)\n",
        "        self.down4 = Down(hidden_dim * 8, hidden_dim * 8)\n",
        "        self.up1 = Up(hidden_dim * 16, hidden_dim * 4)\n",
        "        self.up2 = Up(hidden_dim * 8, hidden_dim * 2)\n",
        "        self.up3 = Up(hidden_dim * 4, hidden_dim)\n",
        "        self.up4 = Up(hidden_dim * 2, hidden_dim)\n",
        "        self.outc = OutConv(hidden_dim, img_channels)\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t = t.view(-1, 1).float() / 1000.0  # scale down\n",
        "        t_emb = self.time_mlp(t)[:, :, None, None]\n",
        "\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        out = self.outc(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc83b981",
      "metadata": {
        "id": "dc83b981"
      },
      "source": [
        "### Model Training\n",
        "- Design a loss function to train for $\\epsilon_t$.\n",
        "- For simplicity MSELoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "07b692e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07b692e3",
        "outputId": "a1747cf1-4f49-4c63-bcf8-c4777faa0480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.1221\n",
            "Epoch [2/20], Loss: 0.0762\n",
            "Epoch [3/20], Loss: 0.0712\n",
            "Epoch [4/20], Loss: 0.0693\n",
            "Epoch [5/20], Loss: 0.0678\n",
            "Epoch [6/20], Loss: 0.0677\n",
            "Epoch [7/20], Loss: 0.0648\n",
            "Epoch [8/20], Loss: 0.0641\n",
            "Epoch [9/20], Loss: 0.0645\n",
            "Epoch [10/20], Loss: 0.0632\n",
            "Epoch [11/20], Loss: 0.0627\n",
            "Epoch [12/20], Loss: 0.0635\n",
            "Epoch [13/20], Loss: 0.0616\n",
            "Epoch [14/20], Loss: 0.0604\n",
            "Epoch [15/20], Loss: 0.0620\n",
            "Epoch [16/20], Loss: 0.0616\n",
            "Epoch [17/20], Loss: 0.0613\n",
            "Epoch [18/20], Loss: 0.0608\n",
            "Epoch [19/20], Loss: 0.0623\n",
            "Epoch [20/20], Loss: 0.0606\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_epochs = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Diffusion().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "T = 30\n",
        "a = 0.9 # decay factor\n",
        "\n",
        "# Use DataLoader for efficient batching\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "\n",
        "        noisy_images, noise, t = Noising(images, T, a)\n",
        "\n",
        "        noise_pred = model(noisy_images, t)\n",
        "\n",
        "        loss = criterion(noise_pred, noise)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)  # accumulate by batch size\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deef38ce",
      "metadata": {
        "id": "deef38ce"
      },
      "source": [
        "**Full Update Rule:**\n",
        "\n",
        "The full denoising update at each step is:\n",
        "\n",
        "$$\n",
        "x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $\\alpha_t$: noise schedule at step $t$\n",
        "- $\\bar{\\alpha}_t$: cumulative product of $\\alpha_t$ up to $t$\n",
        "- $\\epsilon_\\theta(x_t, t)$: predicted noise by the model\n",
        "- $\\sigma_t$: standard deviation for added noise\n",
        "- $z \\sim \\mathcal{N}(0, I)$: random noise\n",
        "\n",
        "This update produces higher fidelity samples by accounting for the variance schedule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "3bc269e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "3bc269e1",
        "outputId": "9fff1cba-6519-45ed-bec4-30e841f538a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def Denoising(model, img_size=(1, 28, 28), T=30, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    betas = torch.linspace(1e-4, 0.02, T, device=device)\n",
        "    alphas = 1.0 - betas\n",
        "    alpha_bar = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "    # pure noise\n",
        "    x_t = torch.randn(1, *img_size, device=device)\n",
        "\n",
        "    for t in reversed(range(T)):\n",
        "        t_tensor = torch.tensor([t], device=device, dtype=torch.long)\n",
        "\n",
        "        # predict noise\n",
        "        eps_theta = model(x_t, t_tensor)\n",
        "\n",
        "        # coefficients\n",
        "        alpha_t = alphas[t]\n",
        "        alpha_bar_t = alpha_bar[t]\n",
        "        beta_t = betas[t]\n",
        "\n",
        "        # mean term μ_θ(x_t, t)\n",
        "        mean = (1.0 / torch.sqrt(alpha_t)) * (\n",
        "            x_t - (beta_t / torch.sqrt(1 - alpha_bar_t)) * eps_theta\n",
        "        )\n",
        "\n",
        "        if t > 0:\n",
        "            # variance term σ_t z\n",
        "            alpha_bar_prev = alpha_bar[t-1] if t > 0 else torch.tensor(1.0, device=device)\n",
        "            posterior_var = beta_t * (1 - alpha_bar_prev) / (1 - alpha_bar_t)\n",
        "            sigma_t = torch.sqrt(posterior_var)\n",
        "            noise = torch.randn_like(x_t)\n",
        "            x_t = mean + sigma_t * noise\n",
        "        else:\n",
        "            # at t=0, just take the mean\n",
        "            x_t = mean\n",
        "\n",
        "    return x_t\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gen_image = Denoising(model, img_size=(1, 28, 28), T=1000, device= device)\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(gen_image.squeeze().cpu(), cmap=\"gray\")\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
