{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcfdff6",
   "metadata": {},
   "source": [
    "# Diffusion Models for Generative AI\n",
    "\n",
    "Diffusion models are a class of generative models that create new data by reversing a process that gradually adds noise. They operate in two main phases:\n",
    "\n",
    "- **Forward Process (Diffusion):** Noise is incrementally added to the original data over $T$ steps, transforming it into pure noise.\n",
    "- **Model Training:** The model learns to predict the noise added at each step, enabling it to understand how to reverse the process.\n",
    "- **Backward Process (Denoising):** Starting from random noise, the model iteratively removes noise over $T$ steps, reconstructing a new, realistic sample.\n",
    "\n",
    "This approach allows diffusion models to generate new high-quality images from a image dataset by simulating the process of denoising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc080f89",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b58621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43e3c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_train = mnist.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = mnist.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac6abf",
   "metadata": {},
   "source": [
    "### Forward Process - Noising\n",
    "\n",
    "Let $x_0$ be the image at t=0, and $x_t$ be the data at timestep $t$ after adding noise. The forward process is defined as:\n",
    "\n",
    "$$x_t = \\sqrt{\\alpha_t} x_{t-1} + \\sqrt{1 - \\alpha_t} \\epsilon_t,\\quad \\epsilon_t \\sim \\mathcal{N}(0, 1)$$\n",
    "\n",
    "$$q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\quad \\beta_t \\mathbf{I}),\\quad t \\sim \\mathcal{N}(0, T)$$\n",
    "\n",
    "\n",
    "\n",
    "where $\\beta_t = 1 - \\alpha_t$ is the variance schedule for timestep $t$.\n",
    "\n",
    "The cumulative process from $x_0$ to $x_t$:\n",
    "\n",
    "$$\n",
    "q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, \\quad (1 - \\bar{\\alpha}_t) \\mathbf{I})\n",
    "$$\n",
    "\n",
    "where $\\alpha_t = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s$.\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "1. **Initialize** $x_0$ as the original data sample.\n",
    "2. **For** $t = 1$ to $T$:\n",
    "    - Sample noise $\\epsilon_t \\sim \\mathcal{N}(0, \\mathbf{I})$\n",
    "    - Compute $x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_t$\n",
    "3. **Return** $x_T$ as the fully noised data.\n",
    "\n",
    "This process gradually transforms the original data into pure noise over $T$ steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b20926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 30  # total timesteps\n",
    "a = 0.1 # noise proportion per step\n",
    "# kept constant for simplicity\n",
    "\n",
    "def Noising(images, T, a):\n",
    "    t = torch.randint(0, T, (images.size(0),), device=images.device).float()\n",
    "    noise = torch.randn_like(images)\n",
    "    a_t = a**t\n",
    "\n",
    "    noisy_images = (a_t.view(-1, 1, 1, 1))**0.5 * images + (1 - a_t).view(-1, 1, 1, 1)**0.5 * noise\n",
    "\n",
    "    return noisy_images, noise , t  # -> this should also be output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ae8b8",
   "metadata": {},
   "source": [
    "### Deep Learning Model ###\n",
    "A simple CNN based model to run over-the image reduse the dimensions and atlast give an output $\\epsilon_t$.\\\n",
    "$\\epsilon_t$ is a prediction of the amount of error introduced. And, the model learns to predict $\\epsilon_t$ better and better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7cb3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Diffusion(nn.Module):\n",
    "    def __init__(self, img_channels=1, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(img_channels, hidden_dim, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, img_channels, 3, padding=1)\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.view(-1, 1).float() / 1000.0  # scale down\n",
    "        t_emb = self.time_mlp(t)[:, :, None, None]\n",
    "\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = h + t_emb\n",
    "        h = F.relu(self.conv2(h))\n",
    "        out = self.conv3(h)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83b981",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "- Design a loss function to train for $\\epsilon_t$.\n",
    "- For simplicity MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b692e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 5\n",
    "device = \"cpu\"\n",
    "\n",
    "model = Diffusion().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "T = 30\n",
    "a = 0.9 # deacay factor\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, _ in mnist_train:\n",
    "        images = images.to(device)\n",
    "\n",
    "        noisy_images, noise, t = Noising(images, T, a)\n",
    "\n",
    "        # model predicts noise for each pixel\n",
    "        noise_pred = model(noisy_images, t)\n",
    "\n",
    "        # loss = MSE between true noise and predicted noise\n",
    "        loss = criterion(noise_pred, noise)\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(mnist_train)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef38ce",
   "metadata": {},
   "source": [
    "**Full Update Rule:**\n",
    "\n",
    "The full denoising update at each step is:\n",
    "\n",
    "$$\n",
    "x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\alpha_t$: noise schedule at step $t$\n",
    "- $\\bar{\\alpha}_t$: cumulative product of $\\alpha_t$ up to $t$\n",
    "- $\\epsilon_\\theta(x_t, t)$: predicted noise by the model\n",
    "- $\\sigma_t$: standard deviation for added noise\n",
    "- $z \\sim \\mathcal{N}(0, I)$: random noise\n",
    "\n",
    "This update produces higher fidelity samples by accounting for the variance schedule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc269e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def Denoising(model, img_size=(1, 28, 28), T=30, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    betas = torch.linspace(1e-4, 0.02, T, device=device)\n",
    "    alphas = 1.0 - betas\n",
    "    alpha_bar = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "    # pure noise\n",
    "    x_t = torch.randn(1, *img_size, device=device)\n",
    "\n",
    "    for t in reversed(range(T)):\n",
    "        t_tensor = torch.tensor([t], device=device, dtype=torch.long)\n",
    "\n",
    "        # predict noise\n",
    "        eps_theta = model(x_t, t_tensor)\n",
    "\n",
    "        # coefficients\n",
    "        alpha_t = alphas[t]\n",
    "        alpha_bar_t = alpha_bar[t]\n",
    "        beta_t = betas[t]\n",
    "\n",
    "        # mean term μ_θ(x_t, t)\n",
    "        mean = (1.0 / torch.sqrt(alpha_t)) * (\n",
    "            x_t - (beta_t / torch.sqrt(1 - alpha_bar_t)) * eps_theta\n",
    "        )\n",
    "\n",
    "        if t > 0:\n",
    "            # variance term σ_t z\n",
    "            alpha_bar_prev = alpha_bar[t-1] if t > 0 else torch.tensor(1.0, device=device)\n",
    "            posterior_var = beta_t * (1 - alpha_bar_prev) / (1 - alpha_bar_t)\n",
    "            sigma_t = torch.sqrt(posterior_var)\n",
    "            noise = torch.randn_like(x_t)\n",
    "            x_t = mean + sigma_t * noise\n",
    "        else:\n",
    "            # at t=0, just take the mean\n",
    "            x_t = mean\n",
    "\n",
    "    return x_t\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gen_image = Denoising(model, img_size=(1, 28, 28), T=30)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(gen_image.squeeze().cpu(), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
